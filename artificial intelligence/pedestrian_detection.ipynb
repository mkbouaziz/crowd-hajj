{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pedestrian detection.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JFN7uxMfDDCY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# pedestrian detection"
      ]
    },
    {
      "metadata": {
        "id": "u8XyQFM50Vop",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This example illustrates how to detect pedestrian using YOLO, and then calculate numbers of pilgrims.  \n",
        "By calculating the number of pilgrims we can calculate density.\n"
      ]
    },
    {
      "metadata": {
        "id": "Y-wljO_r0Voq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initialization\n",
        "Installing, importing libraries"
      ]
    },
    {
      "metadata": {
        "id": "hyRK9Kvh0Xje",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm imgaug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NRt03JuB0Vor",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from tqdm import tqdm_notebook\n",
        "import numpy as np\n",
        "import json\n",
        "import copy\n",
        "import pickle\n",
        "import os, cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "from keras.utils import Sequence\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aI2PQD-E-T6l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating functions that will help us processing Yolo"
      ]
    },
    {
      "metadata": {
        "id": "LqxpbvEV0Vov",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        \n",
        "        self.c     = c\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        \n",
        "        return self.label\n",
        "    \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "            \n",
        "        return self.score\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])  \n",
        "    \n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    \n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    \n",
        "    return float(intersect) / union\n",
        "\n",
        "def draw_boxes(image, boxes, labels):\n",
        "    image_h, image_w, _ = image.shape\n",
        "\n",
        "    for box in boxes:\n",
        "        xmin = int(box.xmin*image_w)\n",
        "        ymin = int(box.ymin*image_h)\n",
        "        xmax = int(box.xmax*image_w)\n",
        "        ymax = int(box.ymax*image_h)\n",
        "\n",
        "        cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (0,255,0), 3)\n",
        "        cv2.putText(image, \n",
        "                    labels[box.get_label()] + ' ' + str(box.get_score()), \n",
        "                    (xmin, ymin - 13), \n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                    1e-3 * image_h, \n",
        "                    (0,255,0), 2)\n",
        "        \n",
        "    return image          \n",
        "        \n",
        "def decode_netout(netout, anchors, nb_class, obj_threshold=0.3, nms_threshold=0.3):\n",
        "    grid_h, grid_w, nb_box = netout.shape[:3]\n",
        "\n",
        "    boxes = []\n",
        "    \n",
        "    # decode the output by the network\n",
        "    netout[..., 4]  = _sigmoid(netout[..., 4])\n",
        "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
        "    \n",
        "    for row in range(grid_h):\n",
        "        for col in range(grid_w):\n",
        "            for b in range(nb_box):\n",
        "                # from 4th element onwards are confidence and class classes\n",
        "                classes = netout[row,col,b,5:]\n",
        "                \n",
        "                if np.sum(classes) > 0:\n",
        "                    # first 4 elements are x, y, w, and h\n",
        "                    x, y, w, h = netout[row,col,b,:4]\n",
        "\n",
        "                    x = (col + _sigmoid(x)) / grid_w # center position, unit: image width\n",
        "                    y = (row + _sigmoid(y)) / grid_h # center position, unit: image height\n",
        "                    w = anchors[2 * b + 0] * np.exp(w) / grid_w # unit: image width\n",
        "                    h = anchors[2 * b + 1] * np.exp(h) / grid_h # unit: image height\n",
        "                    confidence = netout[row,col,b,4]\n",
        "                    \n",
        "                    box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
        "                    \n",
        "                    boxes.append(box)\n",
        "\n",
        "    # suppress non-maximal boxes\n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = list(reversed(np.argsort([box.classes[c] for box in boxes])))\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "            \n",
        "            if boxes[index_i].classes[c] == 0: \n",
        "                continue\n",
        "            else:\n",
        "                for j in range(i+1, len(sorted_indices)):\n",
        "                    index_j = sorted_indices[j]\n",
        "                    \n",
        "                    if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_threshold:\n",
        "                        boxes[index_j].classes[c] = 0\n",
        "                        \n",
        "    # remove the boxes which are less likely than a obj_threshold\n",
        "    boxes = [box for box in boxes if box.get_score() > obj_threshold]\n",
        "    \n",
        "    return boxes  \n",
        "        \n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3          \n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def _softmax(x, axis=-1, t=-100.):\n",
        "    x = x - np.max(x)\n",
        "    \n",
        "    if np.min(x) < t:\n",
        "        x = x/np.min(x)*t\n",
        "        \n",
        "    e_x = np.exp(x)\n",
        "    \n",
        "    return e_x / e_x.sum(axis, keepdims=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M0elpukV0Voy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class BatchGenerator(Sequence):\n",
        "    def __init__(self, images, \n",
        "                       config, \n",
        "                       shuffle=True, \n",
        "                       jitter=True, \n",
        "                       norm=None):\n",
        "        self.generator = None\n",
        "\n",
        "        self.images = images\n",
        "        self.config = config\n",
        "\n",
        "        self.shuffle = shuffle\n",
        "        self.jitter  = jitter\n",
        "        self.norm    = norm\n",
        "\n",
        "        self.anchors = [BoundBox(0, 0, config['ANCHORS'][2*i], config['ANCHORS'][2*i+1]) for i in range(int(len(config['ANCHORS'])//2))]\n",
        "\n",
        "        ### augmentors by https://github.com/aleju/imgaug\n",
        "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\n",
        "        # Define our sequence of augmentation steps that will be applied to every image\n",
        "        # All augmenters with per_channel=0.5 will sample one value _per image_\n",
        "        # in 50% of all cases. In all other cases they will sample new values\n",
        "        # _per channel_.\n",
        "        self.aug_pipe = iaa.Sequential(\n",
        "            [\n",
        "                # apply the following augmenters to most images\n",
        "                # iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
        "                # iaa.Flipud(0.2), # vertically flip 20% of all images\n",
        "                # sometimes(iaa.Crop(percent=(0, 0.1))), # crop images by 0-10% of their height/width\n",
        "                # sometimes(iaa.Affine(\n",
        "                    #scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
        "                    #translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
        "                    #rotate=(-5, 5), # rotate by -45 to +45 degrees\n",
        "                    #shear=(-5, 5), # shear by -16 to +16 degrees\n",
        "                    #order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "                    #cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "                    #mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "                #)),\n",
        "                # execute 0 to 5 of the following (less important) augmenters per image\n",
        "                # don't execute all of them, as that would often be way too strong\n",
        "                iaa.SomeOf((0, 5),\n",
        "                    [\n",
        "                        #sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
        "                        iaa.OneOf([\n",
        "                            iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
        "                            iaa.AverageBlur(k=(1, 3)), # blur image using local means with kernel sizes between 2 and 7\n",
        "                            iaa.MedianBlur(k=(1, 3)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                        ]),\n",
        "                        #iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
        "                        #iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
        "                        # search either for all edges or for directed edges\n",
        "                        #sometimes(iaa.OneOf([\n",
        "                        #    iaa.EdgeDetect(alpha=(0, 0.7)),\n",
        "                        #    iaa.DirectedEdgeDetect(alpha=(0, 0.7), direction=(0.0, 1.0)),\n",
        "                        #])),\n",
        "                        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
        "#                         iaa.OneOf([\n",
        "#                             iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
        "#                             #iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
        "#                         ]),\n",
        "                        iaa.Invert(0.05, per_channel=True), # invert color channels\n",
        "                        iaa.Add((-45, 45), per_channel=0.5), # change brightness of images (by -45 to 45 of original value)\n",
        "                        iaa.Multiply((0.5, 1.5), per_channel=0.5), # change brightness of images (50-150% of original value)\n",
        "                        iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
        "                        #iaa.Grayscale(alpha=(0.0, 1.0)),\n",
        "                        #sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
        "                        #sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))) # sometimes move parts of the image around\n",
        "                    ],\n",
        "                    random_order=True\n",
        "                )\n",
        "            ],\n",
        "            random_order=True\n",
        "        )\n",
        "\n",
        "        if shuffle: np.random.shuffle(self.images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(float(len(self.images))/self.config['BATCH_SIZE']))   \n",
        "\n",
        "    def num_classes(self):\n",
        "        return len(self.config['LABELS'])\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.images)    \n",
        "\n",
        "    def load_annotation(self, i):\n",
        "        annots = []\n",
        "\n",
        "        for obj in self.images[i]['object']:\n",
        "            annot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.config['LABELS'].index(obj['name'])]\n",
        "            annots += [annot]\n",
        "\n",
        "        if len(annots) == 0: annots = [[]]\n",
        "\n",
        "        return np.array(annots)\n",
        "\n",
        "    def load_image(self, i):\n",
        "        return cv2.imread(self.images[i]['filename'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx = idx%(len(self.images)/self.config['BATCH_SIZE'])\n",
        "        l_bound = idx*self.config['BATCH_SIZE']\n",
        "        r_bound = (idx+1)*self.config['BATCH_SIZE']\n",
        "\n",
        "        if r_bound > len(self.images):\n",
        "            r_bound = len(self.images)\n",
        "            l_bound = r_bound - self.config['BATCH_SIZE']\n",
        "\n",
        "        instance_count = 0\n",
        "\n",
        "        x_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_H'], self.config['IMAGE_W'], 3))                         # input images\n",
        "        b_batch = np.zeros((r_bound - l_bound, 1     , 1     , 1    ,  self.config['TRUE_BOX_BUFFER'], 4))   # list of self.config['TRUE_self.config['BOX']_BUFFER'] GT boxes\n",
        "        y_batch = np.zeros((r_bound - l_bound, self.config['GRID_H'],  self.config['GRID_W'], self.config['BOX'], 4+1+len(self.config['LABELS'])))                # desired network output\n",
        "\n",
        "        for train_instance in self.images[l_bound:r_bound]:\n",
        "            # augment input image and fix object's position and size\n",
        "            img, all_objs = self.aug_image(train_instance, jitter=self.jitter)\n",
        "            \n",
        "            # construct output from object's x, y, w, h\n",
        "            true_box_index = 0\n",
        "            \n",
        "            for obj in all_objs:\n",
        "                if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in self.config['LABELS']:\n",
        "                    center_x = .5*(obj['xmin'] + obj['xmax'])\n",
        "                    center_x = center_x / (float(self.config['IMAGE_W']) / self.config['GRID_W'])\n",
        "                    center_y = .5*(obj['ymin'] + obj['ymax'])\n",
        "                    center_y = center_y / (float(self.config['IMAGE_H']) / self.config['GRID_H'])\n",
        "\n",
        "                    grid_x = int(np.floor(center_x))\n",
        "                    grid_y = int(np.floor(center_y))\n",
        "\n",
        "                    if grid_x < self.config['GRID_W'] and grid_y < self.config['GRID_H']:\n",
        "                        obj_indx  = self.config['LABELS'].index(obj['name'])\n",
        "                        \n",
        "                        center_w = (obj['xmax'] - obj['xmin']) / (float(self.config['IMAGE_W']) / self.config['GRID_W']) # unit: grid cell\n",
        "                        center_h = (obj['ymax'] - obj['ymin']) / (float(self.config['IMAGE_H']) / self.config['GRID_H']) # unit: grid cell\n",
        "                        \n",
        "                        box = [center_x, center_y, center_w, center_h]\n",
        "\n",
        "                        # find the anchor that best predicts this box\n",
        "                        best_anchor = -1\n",
        "                        max_iou     = -1\n",
        "                        \n",
        "                        shifted_box = BoundBox(0, \n",
        "                                               0,\n",
        "                                               center_w,                                                \n",
        "                                               center_h)\n",
        "                        \n",
        "                        for i in range(len(self.anchors)):\n",
        "                            anchor = self.anchors[i]\n",
        "                            iou    = bbox_iou(shifted_box, anchor)\n",
        "                            \n",
        "                            if max_iou < iou:\n",
        "                                best_anchor = i\n",
        "                                max_iou     = iou\n",
        "                                \n",
        "                        # assign ground truth x, y, w, h, confidence and class probs to y_batch\n",
        "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 0:4] = box\n",
        "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 4  ] = 1.\n",
        "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 5+obj_indx] = 1\n",
        "                        \n",
        "                        # assign the true box to b_batch\n",
        "                        b_batch[instance_count, 0, 0, 0, true_box_index] = box\n",
        "                        \n",
        "                        true_box_index += 1\n",
        "                        true_box_index = true_box_index % self.config['TRUE_BOX_BUFFER']\n",
        "                            \n",
        "            # assign input image to x_batch\n",
        "            if self.norm != None: \n",
        "                x_batch[instance_count] = self.norm(img)\n",
        "            else:\n",
        "                # plot image and bounding boxes for sanity check\n",
        "                for obj in all_objs:\n",
        "                    if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin']:\n",
        "                        cv2.rectangle(img[:,:,::-1], (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (255,0,0), 3)\n",
        "                        cv2.putText(img[:,:,::-1], obj['name'], \n",
        "                                    (obj['xmin']+2, obj['ymin']+12), \n",
        "                                    0, 1.2e-3 * img.shape[0], \n",
        "                                    (0,255,0), 2)\n",
        "                        \n",
        "                x_batch[instance_count] = img\n",
        "\n",
        "            # increase instance counter in current batch\n",
        "            instance_count += 1  \n",
        "\n",
        "        #print(' new batch created', idx)\n",
        "\n",
        "        return [x_batch, b_batch], y_batch\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle: np.random.shuffle(self.images)\n",
        "\n",
        "    def aug_image(self, train_instance, jitter):\n",
        "        image_name = train_instance['filename']\n",
        "        image = cv2.imread(image_name)\n",
        "\n",
        "        if image is None: print('Cannot find ', image_name)\n",
        "\n",
        "        h, w, c = image.shape\n",
        "        all_objs = copy.deepcopy(train_instance['object'])\n",
        "\n",
        "        if jitter:\n",
        "            ### scale the image\n",
        "            scale = np.random.uniform() / 10. + 1.\n",
        "            image = cv2.resize(image, (0,0), fx = scale, fy = scale)\n",
        "\n",
        "            ### translate the image\n",
        "            max_offx = (scale-1.) * w\n",
        "            max_offy = (scale-1.) * h\n",
        "            offx = int(np.random.uniform() * max_offx)\n",
        "            offy = int(np.random.uniform() * max_offy)\n",
        "            \n",
        "            image = image[offy : (offy + h), offx : (offx + w)]\n",
        "\n",
        "            ### flip the image\n",
        "            flip = np.random.binomial(1, .5)\n",
        "            if flip > 0.5: image = cv2.flip(image, 1)\n",
        "                \n",
        "            image = self.aug_pipe.augment_image(image)            \n",
        "            \n",
        "        # resize the image to standard size\n",
        "        image = cv2.resize(image, (self.config['IMAGE_H'], self.config['IMAGE_W']))\n",
        "        image = image[:,:,::-1]\n",
        "\n",
        "        # fix object's position and size\n",
        "        for obj in all_objs:\n",
        "            for attr in ['xmin', 'xmax']:\n",
        "                if jitter: obj[attr] = int(obj[attr] * scale - offx)\n",
        "                    \n",
        "                obj[attr] = int(obj[attr] * float(self.config['IMAGE_W']) / w)\n",
        "                obj[attr] = max(min(obj[attr], self.config['IMAGE_W']), 0)\n",
        "                \n",
        "            for attr in ['ymin', 'ymax']:\n",
        "                if jitter: obj[attr] = int(obj[attr] * scale - offy)\n",
        "                    \n",
        "                obj[attr] = int(obj[attr] * float(self.config['IMAGE_H']) / h)\n",
        "                obj[attr] = max(min(obj[attr], self.config['IMAGE_H']), 0)\n",
        "\n",
        "            if jitter and flip > 0.5:\n",
        "                xmin = obj['xmin']\n",
        "                obj['xmin'] = self.config['IMAGE_W'] - obj['xmax']\n",
        "                obj['xmax'] = self.config['IMAGE_W'] - xmin\n",
        "                \n",
        "        return image, all_objs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8L3ejutM0ck2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zC9adf5YlG3X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': 'backup-%s.tar.gz' % model_name})\n",
        "uploaded.SetContentFile('backup.tar.gz' )\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDi3fBIC0hSI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget yolo-crowd.tar.gz\n",
        "!tar -xzvf yolo-crowd.tar.gz\n",
        "!rm yolo-crowd.tar.gz\n",
        "# !mkdir -p data\n",
        "# !mv crowd data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B166_5P50Vo5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"data/yolo-crowd/logs/data.json\",\"r\") as f:\n",
        "    data=json.loads(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vs81SSBND_C4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"data/yolo-crowd/images/02cf3786-9bad-4604-9364-2cfaa08fbd55_R_416x416.jpg\")\n",
        "image = image.reshape((1,416,416,3))\n",
        "plt.imshow(image[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n07FCQXaCJYy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# from imgaug import augmenters as iaa\n",
        "# import numpy as np\n",
        "\n",
        "# # fake RGB images\n",
        "# # images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n",
        "\n",
        "# # add a random value from the range (-30, 30) to the first two channels of\n",
        "# # input images (e.g. to the R and G channels)\n",
        "# aug = iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5))\n",
        "\n",
        "# images_aug = aug.augment_images(image)\n",
        "# print images_aug.shape\n",
        "# plt.imshow(images_aug[0])\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u8JSkkMQVUbh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "LABELS = list(set(obj.get(\"name\") for item in data for obj in item['object'] if obj.get(\"name\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zCLoswQ70Vo0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# LABELS = ['pedestrian']\n",
        "\n",
        "IMAGE_H, IMAGE_W = 416, 416\n",
        "GRID_H,  GRID_W  = 13 , 13\n",
        "BOX              = 5\n",
        "CLASS            = len(LABELS)\n",
        "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
        "OBJ_THRESHOLD    = 0.3\n",
        "NMS_THRESHOLD    = 0.3\n",
        "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
        "\n",
        "NO_OBJECT_SCALE  = 1.0\n",
        "OBJECT_SCALE     = 5.0\n",
        "COORD_SCALE      = 1.0\n",
        "CLASS_SCALE      = 1.0\n",
        "\n",
        "BATCH_SIZE       = 16\n",
        "WARM_UP_BATCHES  = 100\n",
        "TRUE_BOX_BUFFER  = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQ4dKNZ10Vo2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Explore the dataset"
      ]
    },
    {
      "metadata": {
        "id": "WKRoxtWL0Vo4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "generator_config = {\n",
        "    'IMAGE_H'         : IMAGE_H, \n",
        "    'IMAGE_W'         : IMAGE_W,\n",
        "    'GRID_H'          : GRID_H,  \n",
        "    'GRID_W'          : GRID_W,\n",
        "    'BOX'             : BOX,\n",
        "    'LABELS'          : LABELS,\n",
        "    'CLASS'           : len(LABELS),\n",
        "    'ANCHORS'         : ANCHORS,\n",
        "    'BATCH_SIZE'      : BATCH_SIZE,\n",
        "    'TRUE_BOX_BUFFER' : 50,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBewP52-0Vo-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Sanity check: show a few images with ground truth boxes overlaid **"
      ]
    },
    {
      "metadata": {
        "id": "7QuH_LzB0Vo_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batches = BatchGenerator(data, generator_config,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qTnEX4xx0VpD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "image = batches[0][0][0][0]\n",
        "plt.imshow(image.astype('uint8'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dGdohVYc0VpG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Split the dataset into the training set and the validation set **"
      ]
    },
    {
      "metadata": {
        "id": "YpfAgeIu0VpI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def normalize(image):\n",
        "    return image/255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XatSqAJV0VpK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_split = int(0.8*len(data))\n",
        "train_batch = BatchGenerator(data[:train_valid_split], generator_config,shuffle=True)\n",
        "valid_batch = BatchGenerator(data[train_valid_split:], generator_config,shuffle=True, norm=normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lRQmXkgd0VpL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Construct the network"
      ]
    },
    {
      "metadata": {
        "id": "F63Q23as0VpO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model_name = 'yolo-crowd-v1'\n",
        "\n",
        "!rm graphs/{model_name}/*\n",
        "!rm models/{model_name}.hdf5\n",
        "\n",
        "output_folder = 'models'\n",
        "\n",
        "model_location = os.path.join(output_folder, model_name+'.hdf5')\n",
        "\n",
        "if os.path.exists(model_location):\n",
        "    print(\"Model exists\")\n",
        "    model = load_model(model_location,custom_objects={'custom_loss':custom_loss})\n",
        "    \n",
        "else:\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "        \n",
        "    print(\"Model Created\")\n",
        "    input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "    true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
        "\n",
        "    # Layer 1\n",
        "    x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
        "    x = BatchNormalization(name='norm_1')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Layer 2\n",
        "    x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_2')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Layer 3\n",
        "    x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_3')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 4\n",
        "    x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_4')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 5\n",
        "    x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_5')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Layer 6\n",
        "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_6')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 7\n",
        "    x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_7')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 8\n",
        "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False, input_shape=(416,416,3))(x)\n",
        "    x = BatchNormalization(name='norm_8')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Layer 9\n",
        "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_9')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 10\n",
        "    x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_10')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 11\n",
        "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_11')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 12\n",
        "    x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_12')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 13\n",
        "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_13')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    skip_connection = x\n",
        "\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Layer 14\n",
        "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_14')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 15\n",
        "    x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_15')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 16\n",
        "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_16')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 17\n",
        "    x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_17')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 18\n",
        "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_18')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 19\n",
        "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_19')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 20\n",
        "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_20')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 21\n",
        "    skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
        "    skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
        "    skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
        "#     skip_connection = Lambda(lambda xi: space_to_depth_x2(xi))(skip_connection)\n",
        "    skip_connection = Lambda(lambda xi: K.tf.space_to_depth(xi, block_size=2))(skip_connection)\n",
        "\n",
        "    x = concatenate([skip_connection, x])\n",
        "\n",
        "    # Layer 22\n",
        "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='norm_22')(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Layer 23\n",
        "    x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
        "    output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
        "\n",
        "    # small hack to allow true_boxes to be registered when Keras build the model \n",
        "    # for more information: https://github.com/fchollet/keras/issues/2790\n",
        "    output = Lambda(lambda args: args[0])([output, true_boxes])\n",
        "\n",
        "    model = Model([input_image, true_boxes], output)\n",
        "    \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0zcITR0y0Vph",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Perform training"
      ]
    },
    {
      "metadata": {
        "id": "crLFPV-o0Vph",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loss function**"
      ]
    },
    {
      "metadata": {
        "id": "FSbjPEfV0Vpi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$\\begin{multline}\n",
        "\\lambda_\\textbf{coord}\n",
        "\\sum_{i = 0}^{S^2}\n",
        "    \\sum_{j = 0}^{B}\n",
        "     L_{ij}^{\\text{obj}}\n",
        "            \\left[\n",
        "            \\left(\n",
        "                x_i - \\hat{x}_i\n",
        "            \\right)^2 +\n",
        "            \\left(\n",
        "                y_i - \\hat{y}_i\n",
        "            \\right)^2\n",
        "            \\right]\n",
        "\\\\\n",
        "+ \\lambda_\\textbf{coord} \n",
        "\\sum_{i = 0}^{S^2}\n",
        "    \\sum_{j = 0}^{B}\n",
        "         L_{ij}^{\\text{obj}}\n",
        "         \\left[\n",
        "        \\left(\n",
        "            \\sqrt{w_i} - \\sqrt{\\hat{w}_i}\n",
        "        \\right)^2 +\n",
        "        \\left(\n",
        "            \\sqrt{h_i} - \\sqrt{\\hat{h}_i}\n",
        "        \\right)^2\n",
        "        \\right]\n",
        "\\\\\n",
        "+ \\sum_{i = 0}^{S^2}\n",
        "    \\sum_{j = 0}^{B}\n",
        "        L_{ij}^{\\text{obj}}\n",
        "        \\left(\n",
        "            C_i - \\hat{C}_i\n",
        "        \\right)^2\n",
        "\\\\\n",
        "+ \\lambda_\\textrm{noobj}\n",
        "\\sum_{i = 0}^{S^2}\n",
        "    \\sum_{j = 0}^{B}\n",
        "    L_{ij}^{\\text{noobj}}\n",
        "        \\left(\n",
        "            C_i - \\hat{C}_i\n",
        "        \\right)^2\n",
        "\\\\\n",
        "+ \\sum_{i = 0}^{S^2}\n",
        "L_i^{\\text{obj}}\n",
        "    \\sum_{c \\in \\textrm{classes}}\n",
        "        \\left(\n",
        "            p_i(c) - \\hat{p}_i(c)\n",
        "        \\right)^2\n",
        "\\end{multline}$$"
      ]
    },
    {
      "metadata": {
        "id": "Wk0RcE_70Vpi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    mask_shape = tf.shape(y_true)[:4]\n",
        "    \n",
        "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
        "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
        "\n",
        "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
        "    \n",
        "    coord_mask = tf.zeros(mask_shape)\n",
        "    conf_mask  = tf.zeros(mask_shape)\n",
        "    class_mask = tf.zeros(mask_shape)\n",
        "    \n",
        "    seen = tf.Variable(0.)\n",
        "    total_recall = tf.Variable(0.)\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust prediction\n",
        "    \"\"\"\n",
        "    ### adjust x and y      \n",
        "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
        "    \n",
        "    ### adjust w and h\n",
        "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
        "    \n",
        "    ### adjust confidence\n",
        "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
        "    \n",
        "    ### adjust class probabilities\n",
        "    pred_box_class = y_pred[..., 5:]\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust ground truth\n",
        "    \"\"\"\n",
        "    ### adjust x and y\n",
        "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
        "    \n",
        "    ### adjust w and h\n",
        "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
        "    \n",
        "    ### adjust confidence\n",
        "    true_wh_half = true_box_wh / 2.\n",
        "    true_mins    = true_box_xy - true_wh_half\n",
        "    true_maxes   = true_box_xy + true_wh_half\n",
        "    \n",
        "    pred_wh_half = pred_box_wh / 2.\n",
        "    pred_mins    = pred_box_xy - pred_wh_half\n",
        "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
        "    \n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    \n",
        "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "    \n",
        "    true_box_conf = iou_scores * y_true[..., 4]\n",
        "    \n",
        "    ### adjust class probabilities\n",
        "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
        "    \n",
        "    \"\"\"\n",
        "    Determine the masks\n",
        "    \"\"\"\n",
        "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
        "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
        "    \n",
        "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
        "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
        "    true_xy = true_boxes[..., 0:2]\n",
        "    true_wh = true_boxes[..., 2:4]\n",
        "    \n",
        "    true_wh_half = true_wh / 2.\n",
        "    true_mins    = true_xy - true_wh_half\n",
        "    true_maxes   = true_xy + true_wh_half\n",
        "    \n",
        "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
        "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
        "    \n",
        "    pred_wh_half = pred_wh / 2.\n",
        "    pred_mins    = pred_xy - pred_wh_half\n",
        "    pred_maxes   = pred_xy + pred_wh_half    \n",
        "    \n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    \n",
        "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "\n",
        "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
        "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
        "    \n",
        "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
        "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
        "    \n",
        "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
        "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
        "    \n",
        "    \"\"\"\n",
        "    Warm-up training\n",
        "    \"\"\"\n",
        "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
        "    seen = tf.assign_add(seen, 1.)\n",
        "    \n",
        "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
        "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
        "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
        "                                   tf.ones_like(coord_mask)],\n",
        "                          lambda: [true_box_xy, \n",
        "                                   true_box_wh,\n",
        "                                   coord_mask])\n",
        "    \n",
        "    \"\"\"\n",
        "    Finalize the loss\n",
        "    \"\"\"\n",
        "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
        "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
        "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
        "    \n",
        "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
        "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
        "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
        "    \n",
        "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
        "    \n",
        "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
        "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
        "\n",
        "    \"\"\"\n",
        "    Debugging code\n",
        "    \"\"\"    \n",
        "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
        "    total_recall = tf.assign_add(total_recall, current_recall) \n",
        "\n",
        "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SaHcb0NY0Vpo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Setup a few callbacks and start the training**"
      ]
    },
    {
      "metadata": {
        "id": "ZHa1uNi72Fmd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# callbacks\n",
        "checkpointer = ModelCheckpoint(\n",
        "    filepath=os.path.join(model_location),\n",
        "    monitor='loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=3, mode='min', verbose=1)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='./graphs/'+model_name, histogram_freq=0,  \n",
        "          write_graph=True, write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RLX-gXlp2kf-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(lr=1e-6, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.0)\n",
        "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
        "# optimizer = RMSprop(lr=1e-5, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "# model compilation\n",
        "model.compile(loss=custom_loss, optimizer=optimizer)\n",
        "# model.compile(loss=custom_loss, optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2HBPDta0Vpw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(generator        = train_batch, \n",
        "                    steps_per_epoch  = 500, \n",
        "                    epochs           = 32, \n",
        "                    #verbose          = 1,\n",
        "                    validation_data  = valid_batch,\n",
        "                    validation_steps = len(valid_batch),\n",
        "                    callbacks        = [checkpointer, tensorboard, early_stop],\n",
        "                    max_queue_size   = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "59YaTHoH30av",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# # summarize history for accuracy\n",
        "# plt.figure(figsize=(8, 6), dpi=100)\n",
        "# plt.plot(history.history['acc'])\n",
        "# plt.plot(history.history['val_acc'])\n",
        "# plt.title('model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.savefig(os.path.join('models','model accuracy.png'))\n",
        "# plt.show()\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(8, 6), dpi=100)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig(os.path.join('models','model loss.png'))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "StOjOsmL38CF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!tar -czvf backup.tar.gz models/ graphs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_EfytnB39KI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': 'backup-%s.tar.gz' % model_name})\n",
        "uploaded.SetContentFile('backup.tar.gz' )\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xW3H3XFX0Vpz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Perform detection on image"
      ]
    },
    {
      "metadata": {
        "id": "l-bTNagd0Vp0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#model.load_weights(\"weights.h5\")\n",
        "\n",
        "dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l0mXJoli0Vp3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "image = cv2.imread('data/yolo-crowd/images/23a5e6be-eab9-409a-a57a-40cf1f6d9bd5_R_416x416.jpeg')\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "input_image = cv2.resize(image, (416, 416))\n",
        "input_image = input_image / 255.\n",
        "input_image = input_image[:,:,::-1]\n",
        "input_image = np.expand_dims(input_image, 0)\n",
        "\n",
        "netout = model.predict([input_image, dummy_array])\n",
        "\n",
        "boxes = decode_netout(netout[0], \n",
        "                      obj_threshold=0.5,\n",
        "                      nms_threshold=NMS_THRESHOLD,\n",
        "                      anchors=ANCHORS, \n",
        "                      nb_class=CLASS)\n",
        "image = draw_boxes(image, boxes, labels=LABELS)\n",
        "\n",
        "plt.imshow(image[:,:,::-1]); plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LRPd2lKqx-ag",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}